{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDNClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5oyUEadlBEpa8U1XFwHF5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LogicPenguins/MachineLearningProjects/blob/master/DDNClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0uWqz5v0EYL"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First lets setup some pre-requisities such as library and module imports, as well as reading in our csv data and initializing some of our testing data structures."
      ],
      "metadata": {
        "id": "6DqkHF8h9vim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "CSV_COLUMNS = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "\n",
        "train_path = tf.keras.utils.get_file(\n",
        "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "test_path = tf.keras.utils.get_file(\n",
        "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "train = pd.read_csv(train_path, names=CSV_COLUMNS, header=0)\n",
        "test = pd.read_csv(test_path, names=CSV_COLUMNS, header=0)\n",
        "\n",
        "train_y = train.pop(\"Species\")\n",
        "test_y = test.pop(\"Species\")\n"
      ],
      "metadata": {
        "id": "XjaG-T-c4Hb9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn(features, labels, training=True, batch_size=256):\n",
        "    # Model needs dataset object below for processing \n",
        "    # Features are the raw data and labels are the y-vals\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "    if training: \n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "\n",
        "    return dataset.batch(batch_size)\n",
        "\n",
        "my_feature_columns = []\n",
        "for key in train.keys():\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    hidden_units=[30, 10],\n",
        "    n_classes=3\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vitJG8h148XR",
        "outputId": "9d2cd711-c25b-4434-befd-ab7f6410e0a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmph5_u2dsj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
        "    steps=5000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW27mJEb7vrI",
        "outputId": "325f40ea-e305-476b-83ca-be688332eac6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fbe61209e10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "86% Accuracy. Not bad!"
      ],
      "metadata": {
        "id": "pk-m0xa09LCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False)\n",
        ")\n",
        "\n",
        "print(f\"\\nAccuracy: {round((100*eval_result['accuracy']), 2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1J1AMV-73-f",
        "outputId": "6c329c31-e02b-4959-f1e3-e704b124ae24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 86.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can make predictions using some simple input code to actually make use of our trained model! \n",
        "\n",
        "Since the input function below is only going to be used for predictions, we don't need to feed y values to it since y values only serve to train the model!"
      ],
      "metadata": {
        "id": "SE4WUyn89CLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn_pred(features, batch_size=256):\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
        "\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
        "predict = {}\n",
        "\n",
        "print('Please type number values as prompted')\n",
        "for feature in features:\n",
        "    while True:\n",
        "        val = input(feature + \": \")\n",
        "        if not val.isdigit(): \n",
        "            break\n",
        "        \n",
        "    predict[feature] = [float(val)]\n",
        "\n",
        "    \n",
        "        \n",
        "\n",
        "# The classifier requires an actual function to be inputted, so we need to \n",
        "# create an anonymous function (aka a lambda) to be able tl pass in the input_fn\n",
        "predictions = classifier.predict(input_fn=lambda: input_fn_pred(predict))\n",
        "for pred_dict in predictions:\n",
        "    class_id = pred_dict['class_ids'][0]\n",
        "    probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "    print(f'Prediction is {SPECIES[class_id]} {round(100 * probability,2)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vDT8esL8eKl",
        "outputId": "385c5c1e-9193-4c8e-fc71-ca159a9265a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please type number values as prompted\n",
            "SepalLength: 3.4\n",
            "SepalWidth: 4.5\n",
            "PetalLength: 3.4\n",
            "PetalWidth: 6.4\n",
            "Prediction is Virginica 98.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After a bit of debugging, it finally works!"
      ],
      "metadata": {
        "id": "D8gooEZTAoS5"
      }
    }
  ]
}